{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiBBKRwft65UwyLf4a9gXf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzsek/One_Number/blob/main/O_N_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captcha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3OKfJRDDxtg",
        "outputId": "d548cfe5-9db4-48eb-b102-c22a414cc6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captcha\n",
            "  Downloading captcha-0.7.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from captcha) (11.3.0)\n",
            "Downloading captcha-0.7.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: captcha\n",
            "Successfully installed captcha-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elyVyPW3DulD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from captcha.image import ImageCaptcha\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import random\n",
        "from pathlib import Path\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/test"
      ],
      "metadata": {
        "id": "bcDR-cS6FY64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = Path('./data/train')\n",
        "# print(train_path)\n",
        "test_path = Path('./data/test')\n",
        "# print(test_path)\n",
        "\n",
        "chars = string.digits\n",
        "\n",
        "image = ImageCaptcha(width = 120, height = 50)\n",
        "\n",
        "for i in range(int(1), int(5001)):\n",
        "  label = ''.join(random.choices(chars))\n",
        "  img = image.generate_image(label)\n",
        "  img.save(train_path / f'{label}_{i}.png')\n",
        "for i in range(int(1), int(1001)):\n",
        "  label = ''.join(random.choices(chars))\n",
        "  img = image.generate_image(label)\n",
        "  img.save(test_path / f'{label}_{i}.png')"
      ],
      "metadata": {
        "id": "jA8PHohmD3kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./data/train/*\n",
        "!rm -rf ./data/test/*"
      ],
      "metadata": {
        "id": "bVNoYyxxEs5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First train image: {os.listdir(train_path)[0]}\\n\",\n",
        "      f\"Train images count: {len(os.listdir(train_path))}\")\n",
        "print(f\"First test image: {os.listdir(test_path)[0]}\\n\",\n",
        "      f\"Test images count: {len(os.listdir(test_path))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVHiNjUxFVck",
        "outputId": "64e7259a-7d48-4719-a5a0-f1a93adf3fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First train image: 1_2791.png\n",
            " Train images count: 5000\n",
            "First test image: 6_139.png\n",
            " Test images count: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = list(train_path.glob('*'))\n",
        "testing_data = list(test_path.glob('*'))"
      ],
      "metadata": {
        "id": "Wg37r0HoIj_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "u0N42v_GORcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "NAuEvDPPjA8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,image_paths,transform):\n",
        "    self.image_paths = image_paths\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_paths = self.image_paths[index]\n",
        "    image = Image.open(image_paths).convert('RGB')\n",
        "    label_str = image_paths.stem.split(\"_\")[0]\n",
        "    label = int(label_str)\n",
        "    return self.transform(image),label"
      ],
      "metadata": {
        "id": "4w5TH2TpNPKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = CustomDataset(training_data, transform = transform)\n",
        "testing_dataset = CustomDataset(testing_data, transform = transform)"
      ],
      "metadata": {
        "id": "l_zlOYRIN8li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{training_dataset}\")\n",
        "print(f\"{testing_dataset}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a427qqvOjvy",
        "outputId": "ad73b207-3fdc-4c1f-ce71-ecce20bc9b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.CustomDataset object at 0x7b82ceb41f10>\n",
            "<__main__.CustomDataset object at 0x7b82ceb41b50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_dataset[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L7hpSq-OlbB",
        "outputId": "7238fa1e-de3d-4939-a890-e74ea0e86170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = DataLoader(training_dataset, batch_size = 64, shuffle = True)\n",
        "testing_loader = DataLoader(testing_dataset, batch_size = 64, shuffle = False)"
      ],
      "metadata": {
        "id": "QjFSeKj3O3Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in training_loader:\n",
        "    print(\"Images batch shape:\", images.shape)\n",
        "    print(\"Labels batch:\", labels)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk80y8MOPvyS",
        "outputId": "efaa8f89-bf44-41d2-af56-3a8631d6f3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images batch shape: torch.Size([64, 3, 50, 120])\n",
            "Labels batch: tensor([4, 4, 3, 8, 2, 3, 0, 2, 3, 5, 9, 5, 9, 0, 4, 1, 9, 1, 8, 6, 5, 4, 7, 1,\n",
            "        2, 2, 9, 8, 7, 5, 6, 5, 8, 2, 2, 3, 8, 9, 4, 0, 8, 5, 2, 1, 7, 8, 8, 8,\n",
            "        8, 1, 1, 8, 5, 5, 6, 3, 0, 7, 1, 0, 1, 1, 4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1_block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "        nn.BatchNorm2d(16)\n",
        "    )\n",
        "    self.conv2_block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "        nn.BatchNorm2d(32)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = 32 * 12 * 30, out_features = 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x = self.conv1_block(x)\n",
        "    # print(x.shape)\n",
        "    # x = self.conv2_block(x)\n",
        "    # print(x.shape)\n",
        "    # x = self.classifier(x)\n",
        "    # print(f\"After flatten: {x.shape}\")\n",
        "    # return x\n",
        "    return self.classifier(self.conv2_block(self.conv1_block(x)))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_0 = CNN().to(device)\n",
        "next(model_0.parameters()).is_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKxOHIP5P084",
        "outputId": "2278f94c-52b8-4070-bf23-1882f90b9832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.Adam(params = model_0.parameters(), lr = 1E-3)"
      ],
      "metadata": {
        "id": "5WX1DQ8-TqrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch: {epoch}\\n----------\")\n",
        "    model_0.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(training_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model_0(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(f\"Batch: {batch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(training_loader)\n",
        "\n",
        "    # Tesztelés az epoch végén\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in testing_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            test_pred = model_0(X)\n",
        "            test_loss += loss_fn(test_pred, y).item()\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(testing_loader)\n",
        "    test_acc /= len(testing_loader)\n",
        "\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml47wRYShbBu",
        "outputId": "a81d7ef1-2b9c-40f1-ac46-45fd3185046b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "----------\n",
            "Batch: 0, Loss: 0.5046\n",
            "Batch: 50, Loss: 0.0830\n",
            "\n",
            "Train loss: 0.15460 | Test loss: 0.08198 | Test acc: 97.99%\n",
            "\n",
            "Epoch: 1\n",
            "----------\n",
            "Batch: 0, Loss: 0.0242\n",
            "Batch: 50, Loss: 0.0075\n",
            "\n",
            "Train loss: 0.01701 | Test loss: 0.05537 | Test acc: 98.83%\n",
            "\n",
            "Epoch: 2\n",
            "----------\n",
            "Batch: 0, Loss: 0.0066\n",
            "Batch: 50, Loss: 0.0043\n",
            "\n",
            "Train loss: 0.00542 | Test loss: 0.03762 | Test acc: 99.51%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVw5sm7HkPG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}